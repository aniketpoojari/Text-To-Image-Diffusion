data:
  raw: data/raw/flowers
  train_size: 2000
  val_size: 200

clip:
  max_length: 77

vae:
  image_size: 128,128

DDPMScheduler:
  T: 1000

unet:
  image_size: 16,16
  in_channels: 4
  out_channels: 4
  down_block_types: CrossAttnDownBlock2D,CrossAttnDownBlock2D,CrossAttnDownBlock2D
  up_block_types: CrossAttnUpBlock2D,CrossAttnUpBlock2D,CrossAttnUpBlock2D
  mid_block_type: UNetMidBlock2DCrossAttn
  block_out_channels: 64,128,256
  layers_per_block: 2
  norm_num_groups: 32
  cross_attention_dim: 512
  attention_head_dim: 12
  dropout: 0.1
  time_embedding_type: positional
  act_fn: silu

training:
  batch_size: 8
  vae_learning_rate: 5e-5
  unet_learning_rate: 1e-3
  weight_decay: 1e-4
  num_epochs: 20

mlflow:
  server_uri: <- Dagshub mlflow url ->
  experiment_name: Training Diffusion
  run_name: 1st
  registered_model_name: Diffusion
  tracking_username: <- Dagshub username ->
  tracking_password: <- Dagshub password ->
  s3_mlruns_bucket: <- s3 bucket to store mlruns data ->

log_trained_model:
  vae_dir: saved_models/vae.pth
  diffuser_dir: saved_models/diffuser.pth

pytorch_estimator:
    entry_point: <- code inside source dir ->
    source_dir: src/code
    framework_version: '2.1.0'
    py_version: py310
    role: <- role arn ->
    instance_count: <- instance count ->
    instance_type: <- instance type ->
    max_wait: 3600
    max_run: 3600
    use_spot_instances: True
    s3_train_data: <- s3 bucket to get training data ->