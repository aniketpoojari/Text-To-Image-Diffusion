schema: '2.0'
stages:
  log_training_model:
    cmd: python src/log_training_model.py --config=params.yaml
    deps:
    - path: src/log_training_model.py
      hash: md5
      md5: 2c4a2341b8d54b7f40b0404a1ddfc677
      size: 5374
    - path: training_completion.txt
      hash: md5
      md5: 739df8c8adcbf65552320903a105b66a
      size: 41
    params:
      params.yaml:
        log_trained_model.diffuser_dir: saved_models/diffuser.pth
        mlflow.experiment_name: Training Diffusion Full
        mlflow.s3_mlruns_bucket: text-to-image-aniket-mlflow
        mlflow.server_uri: https://dagshub.com/aniketpoojari/Text-To-Image-Diffusion.mlflow
    outs:
    - path: saved_models/diffuser.pth
      hash: md5
      md5: c09a4fccc209070d8dd4eb21dbc746b5
      size: 593665094
    - path: saved_models/model_metadata.json
      hash: md5
      md5: 412adca0b3e598e0f0af7f79bff54782
      size: 139
  data-push:
    cmd: python src/upload.py --config=params.yaml
    deps:
    - path: data/raw/flowers/captions
      hash: md5
      md5: 5e47388a2dae57c03ad1167f204bf2b6.dir
      size: 1266107
      nfiles: 8189
    - path: data/raw/flowers/embeddings
      hash: md5
      md5: 8d50d45c37b01b9141df05385ee93fab.dir
      size: 1947123375
      nfiles: 8190
    - path: data/raw/flowers/images
      hash: md5
      md5: 56eae55ec88caaf5b57e6ae9314484d4.dir
      size: 346809251
      nfiles: 8189
    - path: src/upload.py
      hash: md5
      md5: 5b927e90b0bb5647da58230708489492
      size: 3627
    params:
      params.yaml:
        data.raw: data/raw/flowers
        pytorch_estimator.s3_train_data: s3://text-to-image-aniket
    outs:
    - path: upload_completion.txt
      hash: md5
      md5: e7d599c46a30ce31b1616ee67a8d24c7
      size: 141
  ecr-login:
    cmd: aws ecr get-login-password --region us-west-2 | docker login --username AWS
      --password-stdin 975050169307.dkr.ecr.us-west-2.amazonaws.com
    deps:
    - path: src/Dockerfile
      hash: md5
      md5: 908c6c7d442c2ae864f19a077a8e6383
      size: 528
    - path: src/code/dataloader.py
      hash: md5
      md5: 5dd15a065eae81b5867a3509e8215824
      size: 2381
    - path: src/code/training_sagemaker.py
      hash: md5
      md5: 99f0fe90f01f37404defbcf1ca65e10e
      size: 12844
  build-docker:
    cmd: cd src && docker build -t diffusion . && docker tag diffusion:latest 975050169307.dkr.ecr.us-west-2.amazonaws.com/diffusion:latest
    deps:
    - path: src/Dockerfile
      hash: md5
      md5: e0fcb02430e4a776ce52bad6db583680
      size: 2323
    - path: src/dataloader.py
      hash: md5
      md5: 5dd15a065eae81b5867a3509e8215824
      size: 2381
    - path: src/training_sagemaker.py
      hash: md5
      md5: 99f0fe90f01f37404defbcf1ca65e10e
      size: 12844
  docker-push:
    cmd: cd src && docker push 975050169307.dkr.ecr.us-west-2.amazonaws.com/diffusion:latest
    deps:
    - path: src/Dockerfile
      hash: md5
      md5: e0fcb02430e4a776ce52bad6db583680
      size: 2323
    - path: src/dataloader.py
      hash: md5
      md5: 5dd15a065eae81b5867a3509e8215824
      size: 2381
    - path: src/training_sagemaker.py
      hash: md5
      md5: 99f0fe90f01f37404defbcf1ca65e10e
      size: 12844
  caption-generator:
    cmd: python src/caption_generator.py --config=params.yaml
    deps:
    - path: data/raw/flowers/images
      hash: md5
      md5: 56eae55ec88caaf5b57e6ae9314484d4.dir
      size: 346809251
      nfiles: 8189
    - path: src/caption_generator.py
      hash: md5
      md5: 7ac02a05e6492780e8b297739c356ed1
      size: 5489
    params:
      params.yaml:
        data.raw: data/raw/flowers
    outs:
    - path: data/raw/flowers/captions
      hash: md5
      md5: 5e47388a2dae57c03ad1167f204bf2b6.dir
      size: 1266107
      nfiles: 8189
  precompute-embeddings:
    cmd: python src/precompute_embeddings.py --config=params.yaml
    deps:
    - path: data/raw/flowers/captions
      hash: md5
      md5: 5e47388a2dae57c03ad1167f204bf2b6.dir
      size: 1266107
      nfiles: 8189
    - path: data/raw/flowers/images
      hash: md5
      md5: 56eae55ec88caaf5b57e6ae9314484d4.dir
      size: 346809251
      nfiles: 8189
    - path: src/precompute_embeddings.py
      hash: md5
      md5: 04a22cf40b5a52b4fc176d3e9cc4bfe1
      size: 4115
    params:
      params.yaml:
        clip.max_length: 77
        data.raw: data/raw/flowers
    outs:
    - path: data/raw/flowers/embeddings
      hash: md5
      md5: 8d50d45c37b01b9141df05385ee93fab.dir
      size: 1947123375
      nfiles: 8190
  evaluate:
    cmd: python src/evaluate.py --config=params.yaml
    deps:
    - path: saved_models/diffuser.pth
      hash: md5
      md5: c09a4fccc209070d8dd4eb21dbc746b5
      size: 593665094
    - path: src/evaluate.py
      hash: md5
      md5: 4d3eeaa8de2f4bed6acf43939283237b
      size: 4891
    params:
      params.yaml:
        log_trained_model.diffuser_dir: saved_models/diffuser.pth
    outs:
    - path: evaluation_results.json
      hash: md5
      md5: bb3bd87644c807df8835a7a7ae12e7a4
      size: 937
  onnx_convert:
    cmd: python src/onnx_converter.py
    deps:
    - path: evaluation_results.json
      hash: md5
      md5: bb3bd87644c807df8835a7a7ae12e7a4
      size: 937
    - path: saved_models/diffuser.pth
      hash: md5
      md5: c09a4fccc209070d8dd4eb21dbc746b5
      size: 593665094
    - path: src/onnx_converter.py
      hash: md5
      md5: 1d921095390b3c3e94afca2a9482c5b0
      size: 5815
    outs:
    - path: saved_models/onnx_models
      hash: md5
      md5: f731a5d66d1ed55077de39e902bc82ca.dir
      size: 1284636899
      nfiles: 3
  tensorrt_convert:
    cmd: python src/tensorrt_converter.py
    deps:
    - path: saved_models/onnx_models
      hash: md5
      md5: f731a5d66d1ed55077de39e902bc82ca.dir
      size: 1284636899
      nfiles: 3
    - path: src/tensorrt_converter.py
      hash: md5
      md5: ed5007a5fba6540854b42e6d593ab206
      size: 3319
    outs:
    - path: saved_models/trt_models
      hash: md5
      md5: b2f8eea6de1287eb433101d3225f244e.dir
      size: 687159900
      nfiles: 3
  push_to_hub:
    cmd: python src/push_to_hub.py --config=params.yaml
    deps:
    - path: evaluation_results.json
      hash: md5
      md5: bb3bd87644c807df8835a7a7ae12e7a4
      size: 937
    - path: saved_models/diffuser.pth
      hash: md5
      md5: c09a4fccc209070d8dd4eb21dbc746b5
      size: 593665094
    - path: saved_models/onnx_models
      hash: md5
      md5: f731a5d66d1ed55077de39e902bc82ca.dir
      size: 1284636899
      nfiles: 3
    - path: saved_models/trt_models
      hash: md5
      md5: b2f8eea6de1287eb433101d3225f244e.dir
      size: 687159900
      nfiles: 3
    - path: src/push_to_hub.py
      hash: md5
      md5: 722ab9455619840b6b343f53948b4fee
      size: 2635
    params:
      params.yaml:
        huggingface.model_repo: aniketp2009gmail/flower-diffusion
    outs:
    - path: push_completion.txt
      hash: md5
      md5: 9338939b1b4d5baadc10f0c575f1ea3f
      size: 194
  training:
    cmd: python src/trainingjob.py --config=params.yaml
    deps:
    - path: src/code/dataloader.py
      hash: md5
      md5: 9bcca820836ba053825d9365564b7cb8
      size: 7243
    - path: src/code/training_sagemaker_deepspeed.py
      hash: md5
      md5: ef05dbfe2ffe9b807bd3e39c0bf1750a
      size: 24706
    - path: src/trainingjob.py
      hash: md5
      md5: 21e2004bc66607f56fad7c290ebb0c70
      size: 6109
    - path: upload_completion.txt
      hash: md5
      md5: e7d599c46a30ce31b1616ee67a8d24c7
      size: 141
    params:
      params.yaml:
        DDPMScheduler.T: 1000
        clip.max_length: 77
        data.train_size: 7370
        data.val_size: 819
        mlflow.experiment_name: Training Diffusion Full
        mlflow.registered_model_name: Diffusion
        mlflow.run_name: full-data-25ep
        mlflow.s3_mlruns_bucket: text-to-image-aniket-mlflow
        mlflow.server_uri: https://dagshub.com/aniketpoojari/Text-To-Image-Diffusion.mlflow
        mlflow.tracking_password: 38fa619a54d7cdde5e6dcaa55a01a1c14f329bc2
        mlflow.tracking_username: aniketpoojari
        pytorch_estimator.entry_point: training_sagemaker_deepspeed.py
        pytorch_estimator.framework_version: 2.6.0
        pytorch_estimator.instance_count: 2
        pytorch_estimator.instance_type: ml.g5.xlarge
        pytorch_estimator.max_run: 14400
        pytorch_estimator.max_wait: 14400
        pytorch_estimator.py_version: py312
        pytorch_estimator.role: arn:aws:iam::975050169307:role/text-to-image-role
        pytorch_estimator.s3_train_data: s3://text-to-image-aniket
        pytorch_estimator.source_dir: src/code
        pytorch_estimator.use_spot_instances: false
        training.batch_size: 64
        training.num_epochs: 75
        training.unet_learning_rate: 0.0002
        training.weight_decay: 0.01
        unet.act_fn: silu
        unet.attention_head_dim: 8
        unet.block_out_channels: 192,384,576
        unet.cross_attention_dim: 768
        unet.down_block_types: DownBlock2D,CrossAttnDownBlock2D,CrossAttnDownBlock2D
        unet.dropout: 0.0
        unet.image_size: 32,32
        unet.in_channels: 4
        unet.layers_per_block: 2
        unet.mid_block_type: UNetMidBlock2DCrossAttn
        unet.norm_num_groups: 32
        unet.out_channels: 4
        unet.time_embedding_type: positional
        unet.up_block_types: CrossAttnUpBlock2D,CrossAttnUpBlock2D,UpBlock2D
        vae.image_size: 256,256
    outs:
    - path: training_completion.txt
      hash: md5
      md5: 739df8c8adcbf65552320903a105b66a
      size: 41
