stages:
  caption-generator:
    cmd: python src/caption_generator.py --config=params.yaml
    deps:
      - src/caption_generator.py
      - data/raw/flowers/images
    params:
      - data.raw
    outs:
      - data/raw/flowers/captions

  precompute-embeddings:
    cmd: python src/precompute_embeddings.py --config=params.yaml
    deps:
      - src/precompute_embeddings.py
      - data/raw/flowers/images
      - data/raw/flowers/captions
    params:
      - data.raw
      - clip.max_length
    outs:
      - data/raw/flowers/embeddings

  data-push:
    cmd: python src/upload.py --config=params.yaml
    deps:
      - src/upload.py
      - data/raw/flowers/images
      - data/raw/flowers/captions
      - data/raw/flowers/embeddings
    params:
      - data.raw
      - pytorch_estimator.s3_train_data
    outs:
      - upload_completion.txt

  training:
    cmd: python src/trainingjob.py --config=params.yaml
    deps:
      - src/trainingjob.py
      - src/code/dataloader.py
      - src/code/training_sagemaker_deepspeed.py
      - upload_completion.txt
    params:
      - data.train_size
      - data.val_size
      - clip.max_length
      - vae.image_size
      - DDPMScheduler.T
      - unet.image_size
      - unet.in_channels
      - unet.out_channels
      - unet.down_block_types
      - unet.up_block_types
      - unet.mid_block_type
      - unet.block_out_channels
      - unet.layers_per_block
      - unet.norm_num_groups
      - unet.cross_attention_dim
      - unet.attention_head_dim
      - unet.dropout
      - unet.time_embedding_type
      - unet.act_fn
      - training.batch_size
      - training.unet_learning_rate
      - training.weight_decay
      - training.num_epochs
      - mlflow.server_uri
      - mlflow.experiment_name
      - mlflow.run_name
      - mlflow.registered_model_name
      - mlflow.tracking_username
      - mlflow.tracking_password
      - mlflow.s3_mlruns_bucket
      - pytorch_estimator.entry_point
      - pytorch_estimator.source_dir
      - pytorch_estimator.framework_version
      - pytorch_estimator.py_version
      - pytorch_estimator.role
      - pytorch_estimator.instance_count
      - pytorch_estimator.instance_type
      - pytorch_estimator.max_wait
      - pytorch_estimator.max_run
      - pytorch_estimator.use_spot_instances
      - pytorch_estimator.s3_train_data
    outs:
      - training_completion.txt

  log_training_model:
    cmd: python src/log_training_model.py --config=params.yaml
    deps:
      - src/log_training_model.py
      - training_completion.txt
    params:
      - mlflow.server_uri
      - mlflow.experiment_name
      - mlflow.s3_mlruns_bucket
      - log_trained_model.diffuser_dir
    outs:
      - saved_models/diffuser.pth
      - saved_models/model_metadata.json

  evaluate:
    cmd: python src/evaluate.py --config=params.yaml
    deps:
      - src/evaluate.py
      - saved_models/diffuser.pth
    params:
      - log_trained_model.diffuser_dir
    outs:
      - evaluation_results.json

  onnx_convert:
    cmd: python src/onnx_converter.py
    deps:
      - src/onnx_converter.py
      - saved_models/diffuser.pth
      - evaluation_results.json
    outs:
      - saved_models/onnx_models

  tensorrt_convert:
    cmd: python src/tensorrt_converter.py
    deps:
      - src/tensorrt_converter.py
      - saved_models/onnx_models
    outs:
      - saved_models/trt_models

  push_to_hub:
    cmd: python src/push_to_hub.py --config=params.yaml
    deps:
      - src/push_to_hub.py
      - saved_models/diffuser.pth
      - saved_models/onnx_models
      - saved_models/trt_models
      - evaluation_results.json
    params:
      - huggingface.model_repo
    outs:
      - push_completion.txt
